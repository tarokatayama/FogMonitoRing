---
title: "Clean CR800 .dat data file"
author: "Taro Katayama & Brent Wilder"
date: '2022-06-10'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
#run packages
library(dplyr)
library(plyr)
library(tidyverse)
library(lubridate)
library(readr)
library(janitor)
```

```{r}
getwd()
setwd()

stations = list("TP", "SB", "NN", "EB")
for(i in stations){

  # read in all .dat files to csv
  df<-list.files(path = paste("./raw_data/",i,"/", sep = ""),
              pattern="*.dat", 
              full.names = TRUE) %>%
  ldply(read.csv, skip = 1, stringsAsFactors = TRUE)
  # pull only unique rows
  df <- unique(df)
  
  # remove rows containing units/std/avg text
df<- sapply(df, as.numeric)
  
  
  # save files to processed folder
  write.csv(df, file = paste("./processed_data/",i,"/",i,"_processed.csv", sep = ""))
  
}




```

```{r}
# in case you want visual confirmation that code worked
TP_Processed<- read.csv("./processed_data/TP/TP_processed.csv")
NN_Processed<- read.csv("./processed_data/NN/NN_processed.csv")
EB_Processed<- read.csv("./processed_data/EB/EB_processed.csv")
SB_Processed<- read.csv("./processed_data/SB/SB_Processed.csv")
```

