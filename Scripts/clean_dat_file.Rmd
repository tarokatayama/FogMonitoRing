---
title: "Clean CR800 .dat data file"
author: "Taro Katayama & Brent Wilder"
date: '2022-06-10'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
#run packages
library(plyr)
library(tidyverse)
library(lubridate)
library(readr)
library(janitor)
```

```{r}

getwd()
setwd()

stations = list("TP", "SB", "NN", "EB")

for(i in stations){
#combine csv files from raw data folder
  fog_files = list.files(path = paste("./raw_data/",i,"/", sep = ""),
                        pattern= "*.dat", full.names = TRUE)

# turn combination csv files to combined data frame
  fog_combo<- fog_files %>%
  ldply(read.csv, skip = 1, stringsAsFactors = TRUE)

#Take out the first two rows
  fog_combo_clean<-fog_combo[-c(1,2), ]

#pull only unique rows
  fog_combo_processed<-unique(fog_combo_clean)

#Save files to processed folder
  write.csv(fog_combo_processed, file = paste("./processed_data/",i,"/",i,"_processed.csv", sep = ""))
  
}

#in case you want visual confirmation that code worked

TP_Processed<- read.csv("./processed_data/TP/TP_processed.csv")
NN_Processed<- read.csv("./processed_data/NN/NN_processed.csv")
EB_Processed<- read.csv("./processed_data/EB/EB_processed.csv")
SB_Processed<- read.csv("./processed_data/SB/SB_Processed.csv")
```

