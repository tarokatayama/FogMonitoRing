---
title: "Clean CR800 .dat data file"
author: "Taro Katayama & Brent Wilder"
date: '2022-06-10'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
#run packages
library(dplyr)
library(plyr)
library(tidyverse)
library(lubridate)
library(readr)
library(janitor)
```

```{r}
getwd()
setwd()

stations = list("TP", "SB", "NN", "EB")
for(i in stations){

  # read in all .dat files to csv
  df<-list.files(path = paste("./raw_data/",i,"/", sep = ""),
              pattern="*.dat", 
              full.names = TRUE) %>%
  ldply(read.csv, skip = 1)
  
  # change to numeric
  df[-1] <- sapply(df[-1], as.numeric)
  
  # pull only unique rows
  df <- unique(df)
  
  # get rid of empty rows
  df<- subset(df, RECORD >= 0)
  
  # set TIMESTAMP to datetime data type
  df$TIMESTAMP<- as.POSIXct(df$TIMESTAMP, 
                                    tz="", format = "%Y-%m-%d %H:%M")
  
  # save files to processed folder
  write.csv(df, file = paste("./processed_data/",i,"/",i,"_processed_CR800.csv", sep = ""))
  
}

```

```{r}
# in case you want visual confirmation that code worked
TP_Processed<- read.csv("./processed_data/TP/TP_processed_CR800.csv")
NN_Processed<- read.csv("./processed_data/NN/NN_processed_CR800.csv")
EB_Processed<- read.csv("./processed_data/EB/EB_processed_CR800.csv")
SB_Processed<- read.csv("./processed_data/SB/SB_Processed_CR800.csv")
```

